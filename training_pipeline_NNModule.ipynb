{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b21e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ec6057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b9da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b9f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6148de0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf2676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  doing train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8860c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5484237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72567562, -0.07038362, -0.73047326, ..., -0.70765116,\n",
       "         0.2444398 , -0.04898192],\n",
       "       [ 2.08286058, -0.98206509,  2.05932984, ...,  1.28669765,\n",
       "        -0.26695942,  0.16133299],\n",
       "       [ 1.5727387 , -0.27632182,  1.61861579, ...,  1.7179165 ,\n",
       "         1.26388478,  0.46799635],\n",
       "       ...,\n",
       "       [ 0.54962908,  0.90145957,  0.45446546, ..., -0.19954952,\n",
       "         0.09856527,  0.0435126 ],\n",
       "       [ 0.04237306,  0.64924312,  0.19336318, ...,  1.00893747,\n",
       "        -0.07581348,  1.62252611],\n",
       "       [ 1.5297509 , -0.12128969,  1.51051612, ...,  1.4309488 ,\n",
       "         0.63176182,  0.35017596]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d183e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420    B\n",
       "372    M\n",
       "162    M\n",
       "236    M\n",
       "461    M\n",
       "      ..\n",
       "211    B\n",
       "50     B\n",
       "10     M\n",
       "62     M\n",
       "487    M\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce69ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7761da6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc95a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NUMPY ARRAYS TO PYTORCH TENSORS\n",
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "230c23ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0c963e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f084f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features \n",
    "        self.labels = labels\n",
    "        \n",
    "        #  WE WANT FEATURES LENGTH\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    # IN GET ITEM WE WANT FEATURES ID\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc8f43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = customDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed260a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.5326, -0.0033,  1.4440,  1.4819,  0.5494,  0.2923,  0.6339,  0.9980,\n",
       "         -0.1196, -0.8817,  0.6774, -1.1057,  0.4691,  0.6477, -0.7904, -0.4101,\n",
       "         -0.1508,  0.1595, -0.8446, -0.4563,  1.9842, -0.1958,  1.7127,  1.9376,\n",
       "          0.8078,  0.4075,  0.7621,  1.3373,  0.8212,  0.3177]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e21fe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE ARE DEFINING THE MODEL\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MySimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        \n",
    "        super().__init__()\n",
    "        # here one is output\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, features):\n",
    "        \n",
    "        out = self.linear(features)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfd9e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d3cf225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# define optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae928618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.7895793318748474\n",
      "epoch: 1, loss: 0.6257895231246948\n",
      "epoch: 1, loss: 0.5880180597305298\n",
      "epoch: 1, loss: 0.4570196568965912\n",
      "epoch: 1, loss: 0.37624552845954895\n",
      "epoch: 1, loss: 0.30937373638153076\n",
      "epoch: 1, loss: 0.29521289467811584\n",
      "epoch: 1, loss: 0.3432449698448181\n",
      "epoch: 1, loss: 0.2690885066986084\n",
      "epoch: 1, loss: 0.2311791032552719\n",
      "epoch: 1, loss: 0.3001691401004791\n",
      "epoch: 1, loss: 0.22267648577690125\n",
      "epoch: 1, loss: 0.2928931713104248\n",
      "epoch: 1, loss: 0.28683745861053467\n",
      "epoch: 1, loss: 0.1810200959444046\n",
      "epoch: 2, loss: 0.2750813961029053\n",
      "epoch: 2, loss: 0.19377589225769043\n",
      "epoch: 2, loss: 0.16952651739120483\n",
      "epoch: 2, loss: 0.22596776485443115\n",
      "epoch: 2, loss: 0.15691892802715302\n",
      "epoch: 2, loss: 0.15486253798007965\n",
      "epoch: 2, loss: 0.13500897586345673\n",
      "epoch: 2, loss: 0.1990312933921814\n",
      "epoch: 2, loss: 0.2181505262851715\n",
      "epoch: 2, loss: 0.20481184124946594\n",
      "epoch: 2, loss: 0.12868544459342957\n",
      "epoch: 2, loss: 0.2142258733510971\n",
      "epoch: 2, loss: 0.15148067474365234\n",
      "epoch: 2, loss: 0.2150149792432785\n",
      "epoch: 2, loss: 0.09827526658773422\n",
      "epoch: 3, loss: 0.15484517812728882\n",
      "epoch: 3, loss: 0.2127978503704071\n",
      "epoch: 3, loss: 0.11058566719293594\n",
      "epoch: 3, loss: 0.10966668277978897\n",
      "epoch: 3, loss: 0.13811764121055603\n",
      "epoch: 3, loss: 0.12826980650424957\n",
      "epoch: 3, loss: 0.11303608119487762\n",
      "epoch: 3, loss: 0.1626160889863968\n",
      "epoch: 3, loss: 0.11692363768815994\n",
      "epoch: 3, loss: 0.18360857665538788\n",
      "epoch: 3, loss: 0.24333353340625763\n",
      "epoch: 3, loss: 0.11026747524738312\n",
      "epoch: 3, loss: 0.15439099073410034\n",
      "epoch: 3, loss: 0.12915700674057007\n",
      "epoch: 3, loss: 0.13671408593654633\n",
      "epoch: 4, loss: 0.11643221229314804\n",
      "epoch: 4, loss: 0.10398336499929428\n",
      "epoch: 4, loss: 0.14655371010303497\n",
      "epoch: 4, loss: 0.18386514484882355\n",
      "epoch: 4, loss: 0.11109394580125809\n",
      "epoch: 4, loss: 0.10268400609493256\n",
      "epoch: 4, loss: 0.14429667592048645\n",
      "epoch: 4, loss: 0.055436380207538605\n",
      "epoch: 4, loss: 0.19870716333389282\n",
      "epoch: 4, loss: 0.13680407404899597\n",
      "epoch: 4, loss: 0.12926392257213593\n",
      "epoch: 4, loss: 0.09002742916345596\n",
      "epoch: 4, loss: 0.11655869334936142\n",
      "epoch: 4, loss: 0.14904451370239258\n",
      "epoch: 4, loss: 0.12448226660490036\n",
      "epoch: 5, loss: 0.09649501740932465\n",
      "epoch: 5, loss: 0.18664564192295074\n",
      "epoch: 5, loss: 0.13387827575206757\n",
      "epoch: 5, loss: 0.10641931742429733\n",
      "epoch: 5, loss: 0.13828209042549133\n",
      "epoch: 5, loss: 0.11406510323286057\n",
      "epoch: 5, loss: 0.09800727665424347\n",
      "epoch: 5, loss: 0.08380907028913498\n",
      "epoch: 5, loss: 0.06736837327480316\n",
      "epoch: 5, loss: 0.08784961700439453\n",
      "epoch: 5, loss: 0.10581929981708527\n",
      "epoch: 5, loss: 0.08509097993373871\n",
      "epoch: 5, loss: 0.2432064563035965\n",
      "epoch: 5, loss: 0.07958070933818817\n",
      "epoch: 5, loss: 0.02958470769226551\n",
      "epoch: 6, loss: 0.16328378021717072\n",
      "epoch: 6, loss: 0.1411294937133789\n",
      "epoch: 6, loss: 0.051606424152851105\n",
      "epoch: 6, loss: 0.04738808795809746\n",
      "epoch: 6, loss: 0.0990336686372757\n",
      "epoch: 6, loss: 0.11155061423778534\n",
      "epoch: 6, loss: 0.08097456395626068\n",
      "epoch: 6, loss: 0.09888534247875214\n",
      "epoch: 6, loss: 0.12997940182685852\n",
      "epoch: 6, loss: 0.09623471647500992\n",
      "epoch: 6, loss: 0.15906782448291779\n",
      "epoch: 6, loss: 0.13593213260173798\n",
      "epoch: 6, loss: 0.14942854642868042\n",
      "epoch: 6, loss: 0.043171487748622894\n",
      "epoch: 6, loss: 0.0236508846282959\n",
      "epoch: 7, loss: 0.07362280786037445\n",
      "epoch: 7, loss: 0.06522886455059052\n",
      "epoch: 7, loss: 0.12403719127178192\n",
      "epoch: 7, loss: 0.08453971892595291\n",
      "epoch: 7, loss: 0.10322480648756027\n",
      "epoch: 7, loss: 0.14541932940483093\n",
      "epoch: 7, loss: 0.07561875879764557\n",
      "epoch: 7, loss: 0.08438942581415176\n",
      "epoch: 7, loss: 0.09566079080104828\n",
      "epoch: 7, loss: 0.09966813027858734\n",
      "epoch: 7, loss: 0.08439406752586365\n",
      "epoch: 7, loss: 0.16732855141162872\n",
      "epoch: 7, loss: 0.09404371678829193\n",
      "epoch: 7, loss: 0.1110687330365181\n",
      "epoch: 7, loss: 0.07184191048145294\n",
      "epoch: 8, loss: 0.07770954817533493\n",
      "epoch: 8, loss: 0.06402963399887085\n",
      "epoch: 8, loss: 0.09019115567207336\n",
      "epoch: 8, loss: 0.09535373747348785\n",
      "epoch: 8, loss: 0.10652150213718414\n",
      "epoch: 8, loss: 0.12478947639465332\n",
      "epoch: 8, loss: 0.13145482540130615\n",
      "epoch: 8, loss: 0.08247298747301102\n",
      "epoch: 8, loss: 0.10969910770654678\n",
      "epoch: 8, loss: 0.09819076955318451\n",
      "epoch: 8, loss: 0.09359518438577652\n",
      "epoch: 8, loss: 0.06523949652910233\n",
      "epoch: 8, loss: 0.11820656806230545\n",
      "epoch: 8, loss: 0.07957279682159424\n",
      "epoch: 8, loss: 0.05749724060297012\n",
      "epoch: 9, loss: 0.08093652874231339\n",
      "epoch: 9, loss: 0.07365546375513077\n",
      "epoch: 9, loss: 0.12064114212989807\n",
      "epoch: 9, loss: 0.10182570666074753\n",
      "epoch: 9, loss: 0.07822893559932709\n",
      "epoch: 9, loss: 0.07296296954154968\n",
      "epoch: 9, loss: 0.07591685652732849\n",
      "epoch: 9, loss: 0.08905990421772003\n",
      "epoch: 9, loss: 0.10074054449796677\n",
      "epoch: 9, loss: 0.1412198394536972\n",
      "epoch: 9, loss: 0.04526757448911667\n",
      "epoch: 9, loss: 0.09272933751344681\n",
      "epoch: 9, loss: 0.12078099697828293\n",
      "epoch: 9, loss: 0.06993298977613449\n",
      "epoch: 9, loss: 0.11996375769376755\n",
      "epoch: 10, loss: 0.13564611971378326\n",
      "epoch: 10, loss: 0.07584922015666962\n",
      "epoch: 10, loss: 0.06800338625907898\n",
      "epoch: 10, loss: 0.05711493268609047\n",
      "epoch: 10, loss: 0.05922506004571915\n",
      "epoch: 10, loss: 0.12993906438350677\n",
      "epoch: 10, loss: 0.10708054155111313\n",
      "epoch: 10, loss: 0.1487278938293457\n",
      "epoch: 10, loss: 0.08422474563121796\n",
      "epoch: 10, loss: 0.08555871993303299\n",
      "epoch: 10, loss: 0.04948071390390396\n",
      "epoch: 10, loss: 0.052612222731113434\n",
      "epoch: 10, loss: 0.10362885892391205\n",
      "epoch: 10, loss: 0.07475067675113678\n",
      "epoch: 10, loss: 0.03472105413675308\n",
      "epoch: 11, loss: 0.11696569621562958\n",
      "epoch: 11, loss: 0.06664859503507614\n",
      "epoch: 11, loss: 0.05571877583861351\n",
      "epoch: 11, loss: 0.07887521386146545\n",
      "epoch: 11, loss: 0.07716520130634308\n",
      "epoch: 11, loss: 0.15163613855838776\n",
      "epoch: 11, loss: 0.12588191032409668\n",
      "epoch: 11, loss: 0.05759676173329353\n",
      "epoch: 11, loss: 0.088957279920578\n",
      "epoch: 11, loss: 0.0964597687125206\n",
      "epoch: 11, loss: 0.03064393252134323\n",
      "epoch: 11, loss: 0.1071942001581192\n",
      "epoch: 11, loss: 0.05943882837891579\n",
      "epoch: 11, loss: 0.08016493916511536\n",
      "epoch: 11, loss: 0.02958374284207821\n",
      "epoch: 12, loss: 0.1150752380490303\n",
      "epoch: 12, loss: 0.13768668472766876\n",
      "epoch: 12, loss: 0.06493298709392548\n",
      "epoch: 12, loss: 0.06273840367794037\n",
      "epoch: 12, loss: 0.10346061736345291\n",
      "epoch: 12, loss: 0.09032373875379562\n",
      "epoch: 12, loss: 0.15412630140781403\n",
      "epoch: 12, loss: 0.09010999649763107\n",
      "epoch: 12, loss: 0.06977737694978714\n",
      "epoch: 12, loss: 0.037075225263834\n",
      "epoch: 12, loss: 0.04121558368206024\n",
      "epoch: 12, loss: 0.04246588051319122\n",
      "epoch: 12, loss: 0.05314368009567261\n",
      "epoch: 12, loss: 0.09362927079200745\n",
      "epoch: 12, loss: 0.021427584812045097\n",
      "epoch: 13, loss: 0.05433131754398346\n",
      "epoch: 13, loss: 0.07468000799417496\n",
      "epoch: 13, loss: 0.100547656416893\n",
      "epoch: 13, loss: 0.08442772179841995\n",
      "epoch: 13, loss: 0.04011765122413635\n",
      "epoch: 13, loss: 0.08815132826566696\n",
      "epoch: 13, loss: 0.09368981420993805\n",
      "epoch: 13, loss: 0.05178489908576012\n",
      "epoch: 13, loss: 0.11462919414043427\n",
      "epoch: 13, loss: 0.035962268710136414\n",
      "epoch: 13, loss: 0.06875142455101013\n",
      "epoch: 13, loss: 0.09716886281967163\n",
      "epoch: 13, loss: 0.11293701082468033\n",
      "epoch: 13, loss: 0.10682355612516403\n",
      "epoch: 13, loss: 0.027186153456568718\n",
      "epoch: 14, loss: 0.027670083567500114\n",
      "epoch: 14, loss: 0.06290584802627563\n",
      "epoch: 14, loss: 0.05490443855524063\n",
      "epoch: 14, loss: 0.19290512800216675\n",
      "epoch: 14, loss: 0.12709373235702515\n",
      "epoch: 14, loss: 0.07122974097728729\n",
      "epoch: 14, loss: 0.09971076250076294\n",
      "epoch: 14, loss: 0.0870901420712471\n",
      "epoch: 14, loss: 0.06239038705825806\n",
      "epoch: 14, loss: 0.05400709807872772\n",
      "epoch: 14, loss: 0.05335746705532074\n",
      "epoch: 14, loss: 0.04104918614029884\n",
      "epoch: 14, loss: 0.09239093959331512\n",
      "epoch: 14, loss: 0.06853023916482925\n",
      "epoch: 14, loss: 0.021437224000692368\n",
      "epoch: 15, loss: 0.07084273546934128\n",
      "epoch: 15, loss: 0.04630538076162338\n",
      "epoch: 15, loss: 0.05664770305156708\n",
      "epoch: 15, loss: 0.0691431313753128\n",
      "epoch: 15, loss: 0.10490977764129639\n",
      "epoch: 15, loss: 0.0444771982729435\n",
      "epoch: 15, loss: 0.06870792806148529\n",
      "epoch: 15, loss: 0.08004815876483917\n",
      "epoch: 15, loss: 0.0519048236310482\n",
      "epoch: 15, loss: 0.14737090468406677\n",
      "epoch: 15, loss: 0.06443670392036438\n",
      "epoch: 15, loss: 0.13959240913391113\n",
      "epoch: 15, loss: 0.09242016077041626\n",
      "epoch: 15, loss: 0.035293154418468475\n",
      "epoch: 15, loss: 0.017451602965593338\n",
      "epoch: 16, loss: 0.057638127356767654\n",
      "epoch: 16, loss: 0.06023797020316124\n",
      "epoch: 16, loss: 0.04825752601027489\n",
      "epoch: 16, loss: 0.11811815202236176\n",
      "epoch: 16, loss: 0.06834885478019714\n",
      "epoch: 16, loss: 0.02352442778646946\n",
      "epoch: 16, loss: 0.10251156985759735\n",
      "epoch: 16, loss: 0.03761572390794754\n",
      "epoch: 16, loss: 0.08851104974746704\n",
      "epoch: 16, loss: 0.061984919011592865\n",
      "epoch: 16, loss: 0.1430111825466156\n",
      "epoch: 16, loss: 0.12368395924568176\n",
      "epoch: 16, loss: 0.07246579229831696\n",
      "epoch: 16, loss: 0.041262831538915634\n",
      "epoch: 16, loss: 0.022233935073018074\n",
      "epoch: 17, loss: 0.07707200944423676\n",
      "epoch: 17, loss: 0.07483918964862823\n",
      "epoch: 17, loss: 0.0431995689868927\n",
      "epoch: 17, loss: 0.08848205208778381\n",
      "epoch: 17, loss: 0.015666816383600235\n",
      "epoch: 17, loss: 0.1696510910987854\n",
      "epoch: 17, loss: 0.06495487689971924\n",
      "epoch: 17, loss: 0.04703826084733009\n",
      "epoch: 17, loss: 0.05649762228131294\n",
      "epoch: 17, loss: 0.1259198635816574\n",
      "epoch: 17, loss: 0.11804139614105225\n",
      "epoch: 17, loss: 0.06652863323688507\n",
      "epoch: 17, loss: 0.018908513709902763\n",
      "epoch: 17, loss: 0.054788630455732346\n",
      "epoch: 17, loss: 0.04402611777186394\n",
      "epoch: 18, loss: 0.09490030258893967\n",
      "epoch: 18, loss: 0.14362139999866486\n",
      "epoch: 18, loss: 0.028556272387504578\n",
      "epoch: 18, loss: 0.17011861503124237\n",
      "epoch: 18, loss: 0.04959934949874878\n",
      "epoch: 18, loss: 0.09418078511953354\n",
      "epoch: 18, loss: 0.0889972597360611\n",
      "epoch: 18, loss: 0.03635457903146744\n",
      "epoch: 18, loss: 0.03591800108551979\n",
      "epoch: 18, loss: 0.05650505796074867\n",
      "epoch: 18, loss: 0.08330699801445007\n",
      "epoch: 18, loss: 0.03547682240605354\n",
      "epoch: 18, loss: 0.032846592366695404\n",
      "epoch: 18, loss: 0.05711706355214119\n",
      "epoch: 18, loss: 0.02916541136801243\n",
      "epoch: 19, loss: 0.0627855733036995\n",
      "epoch: 19, loss: 0.11450086534023285\n",
      "epoch: 19, loss: 0.11262331157922745\n",
      "epoch: 19, loss: 0.0822426825761795\n",
      "epoch: 19, loss: 0.041762519627809525\n",
      "epoch: 19, loss: 0.044218022376298904\n",
      "epoch: 19, loss: 0.05930822342634201\n",
      "epoch: 19, loss: 0.09366945922374725\n",
      "epoch: 19, loss: 0.03578069061040878\n",
      "epoch: 19, loss: 0.031237462535500526\n",
      "epoch: 19, loss: 0.078799307346344\n",
      "epoch: 19, loss: 0.12623117864131927\n",
      "epoch: 19, loss: 0.03231480345129967\n",
      "epoch: 19, loss: 0.026023924350738525\n",
      "epoch: 19, loss: 0.2557407319545746\n",
      "epoch: 20, loss: 0.09096404165029526\n",
      "epoch: 20, loss: 0.044316258281469345\n",
      "epoch: 20, loss: 0.09918179363012314\n",
      "epoch: 20, loss: 0.08759307861328125\n",
      "epoch: 20, loss: 0.07786213606595993\n",
      "epoch: 20, loss: 0.06408938765525818\n",
      "epoch: 20, loss: 0.04994760453701019\n",
      "epoch: 20, loss: 0.04959104210138321\n",
      "epoch: 20, loss: 0.04033638536930084\n",
      "epoch: 20, loss: 0.09922457486391068\n",
      "epoch: 20, loss: 0.054762840270996094\n",
      "epoch: 20, loss: 0.05778779834508896\n",
      "epoch: 20, loss: 0.036821458488702774\n",
      "epoch: 20, loss: 0.1057855561375618\n",
      "epoch: 20, loss: 0.10932035744190216\n",
      "epoch: 21, loss: 0.03991484269499779\n",
      "epoch: 21, loss: 0.11660483479499817\n",
      "epoch: 21, loss: 0.07733924686908722\n",
      "epoch: 21, loss: 0.05804973095655441\n",
      "epoch: 21, loss: 0.06600135564804077\n",
      "epoch: 21, loss: 0.07211000472307205\n",
      "epoch: 21, loss: 0.076307512819767\n",
      "epoch: 21, loss: 0.07356603443622589\n",
      "epoch: 21, loss: 0.09263946115970612\n",
      "epoch: 21, loss: 0.046901099383831024\n",
      "epoch: 21, loss: 0.0567704476416111\n",
      "epoch: 21, loss: 0.08365478366613388\n",
      "epoch: 21, loss: 0.06119971722364426\n",
      "epoch: 21, loss: 0.04114937037229538\n",
      "epoch: 21, loss: 0.01148360688239336\n",
      "epoch: 22, loss: 0.0402858629822731\n",
      "epoch: 22, loss: 0.013374975882470608\n",
      "epoch: 22, loss: 0.12030166387557983\n",
      "epoch: 22, loss: 0.020248251035809517\n",
      "epoch: 22, loss: 0.11807791888713837\n",
      "epoch: 22, loss: 0.06098656356334686\n",
      "epoch: 22, loss: 0.05511512607336044\n",
      "epoch: 22, loss: 0.05221903324127197\n",
      "epoch: 22, loss: 0.13303445279598236\n",
      "epoch: 22, loss: 0.04081052169203758\n",
      "epoch: 22, loss: 0.06374502182006836\n",
      "epoch: 22, loss: 0.052136458456516266\n",
      "epoch: 22, loss: 0.05061086267232895\n",
      "epoch: 22, loss: 0.12141159176826477\n",
      "epoch: 22, loss: 0.03872065618634224\n",
      "epoch: 23, loss: 0.0861518532037735\n",
      "epoch: 23, loss: 0.020386094227433205\n",
      "epoch: 23, loss: 0.07021908462047577\n",
      "epoch: 23, loss: 0.027340291067957878\n",
      "epoch: 23, loss: 0.05136154219508171\n",
      "epoch: 23, loss: 0.019669249653816223\n",
      "epoch: 23, loss: 0.1785740852355957\n",
      "epoch: 23, loss: 0.08279459178447723\n",
      "epoch: 23, loss: 0.04401189833879471\n",
      "epoch: 23, loss: 0.09221964329481125\n",
      "epoch: 23, loss: 0.12959250807762146\n",
      "epoch: 23, loss: 0.054427795112133026\n",
      "epoch: 23, loss: 0.027486121281981468\n",
      "epoch: 23, loss: 0.04212460666894913\n",
      "epoch: 23, loss: 0.05534067749977112\n",
      "epoch: 24, loss: 0.06484352797269821\n",
      "epoch: 24, loss: 0.09354119747877121\n",
      "epoch: 24, loss: 0.03534814342856407\n",
      "epoch: 24, loss: 0.0663125291466713\n",
      "epoch: 24, loss: 0.10800980031490326\n",
      "epoch: 24, loss: 0.022460702806711197\n",
      "epoch: 24, loss: 0.058729007840156555\n",
      "epoch: 24, loss: 0.10155163705348969\n",
      "epoch: 24, loss: 0.041138533502817154\n",
      "epoch: 24, loss: 0.03318934887647629\n",
      "epoch: 24, loss: 0.07347241044044495\n",
      "epoch: 24, loss: 0.10770536214113235\n",
      "epoch: 24, loss: 0.034816157072782516\n",
      "epoch: 24, loss: 0.07560877501964569\n",
      "epoch: 24, loss: 0.038763485848903656\n",
      "epoch: 25, loss: 0.0640985518693924\n",
      "epoch: 25, loss: 0.052816085517406464\n",
      "epoch: 25, loss: 0.06250106543302536\n",
      "epoch: 25, loss: 0.0952804833650589\n",
      "epoch: 25, loss: 0.048075295984745026\n",
      "epoch: 25, loss: 0.04265991970896721\n",
      "epoch: 25, loss: 0.11002378165721893\n",
      "epoch: 25, loss: 0.06030828505754471\n",
      "epoch: 25, loss: 0.05956374481320381\n",
      "epoch: 25, loss: 0.01695925183594227\n",
      "epoch: 25, loss: 0.09181685745716095\n",
      "epoch: 25, loss: 0.14418457448482513\n",
      "epoch: 25, loss: 0.03018978424370289\n",
      "epoch: 25, loss: 0.01529164332896471\n",
      "epoch: 25, loss: 0.08559493720531464\n"
     ]
    }
   ],
   "source": [
    "# TRAINING PIPLEINE \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        \n",
    "        # loss function\n",
    "        loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # parameters update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss in each epoch\n",
    "        print(f'epoch: {epoch+1}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d9ec06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9509\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "\n",
    "model.eval()\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bae3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
